DEVICE: mps

VERBOSE_LOGGING: False 

CHUNK_SIZE: 1000
CHUNK_OVERLAP: 150
SEPARATORS: ["\n\n", "\n", ". ", " ", ""]

TEXT_SPLIT_MODE: simple
# TEXT_SPLIT_MODE: parent_document
# TEXT_SPLIT_MODE: propositionize

PARENT_DOCS_PATH: ./data/parent_docs.pkl

MODELS_DIR: ./models

EMBEDDINGS_PATH: all-mpnet-base-v2
# EMBEDDINGS_PATH: bge-small-en-v1.5
# EMBEDDINGS_PATH: all-MiniLM-L6-v2

USE_OPENAI: False
# LLM_PATH: gpt-4-0125-preview
# PROMPT_TYPE: gpt-4

# VECTORDB_TYPE: faiss
#VECTORDB_PATH: vectordb/faiss
# VECTORDB_TYPE: chroma
# VECTORDB_PATH: vectordb/chroma
VECTORDB_TYPE: pgvector
VECTORDB_PATH: postgresql+psycopg2://postgres:mysecretpassword@localhost:5432/postgres
COLLECTION_NAME: pdf_document_chunks

# USE_CTRANSFORMERS: True
# LLM_PATH: llama-2-7b-chat.Q4_K_M.gguf
# PROMPT_TYPE: llama

# USE_CTRANSFORMERS: false
# LLM_PATH: mistral-7b-instruct-v0.2.Q4_K_M.gguf
# PROMPT_TYPE: mistral

USE_CTRANSFORMERS: False
#LLM_PATH: openhermes-2.5-mistral-7b.Q4_K_M.gguf
LLM_PATH: openhermes-2.5-mistral-7b.Q8_0.gguf
PROMPT_TYPE: ChatML

# USE_CTRANSFORMERS: True
# LLM_PATH: zephyr-7b-beta.Q4_K_M.gguf
# PROMPT_TYPE: zephyr

# USE_CTRANSFORMERS: False
# LLM_PATH: gemma-2b-it-q4_k_m.gguf
# PROMPT_TYPE: gemma

LLM_CONFIG:
  MAX_NEW_TOKENS: 1024
  TEMPERATURE: 0.1
  REPETITION_PENALTY: 1.1
  CONTEXT_LENGTH: 4096
  N_GPU_LAYERS: -1

BASE_RETRIEVER_CONFIG:
  SEARCH_K: 5

# RERANKER_PATH: tart-full-flan-t5-xl
# RERANKER_TYPE: tart
RERANKER_PATH: bge-reranker-base
RERANKER_TYPE: bge

RERANK_RETRIEVER_CONFIG:
  SEARCH_K: 10
  TOP_N: 5

COMPRESSION_RETRIEVER_CONFIG:
  SEARCH_K: 10
  SIMILARITY_THRESHOLD: 0.5

PROPOSITIONIZER_PATH: propositionizer-wiki-flan-t5-large
PROPOSITIONIZER_CONFIG:
  CHUNK_SIZE: 1000
  CHUNK_OVERLAP: 0

